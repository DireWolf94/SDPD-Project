{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('sign_mnist_train.csv')\n",
    "test = pd.read_csv('sign_mnist_test.csv')\n",
    "labels = train['label'].values\n",
    "train.drop('label', axis = 1, inplace = True)\n",
    "\n",
    "images = train.values\n",
    "images = np.array([np.reshape(i, (28, 28)) for i in images])\n",
    "images = np.array([i.flatten() for i in images])\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "label_binrizer = LabelBinarizer()\n",
    "labels = label_binrizer.fit_transform(labels)\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout,Input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size = 0.3, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 24\n",
    "epochs = 50\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28)\n",
    "x_train = np.stack((x_train,)*3, axis=-1)\n",
    "x_test = np.stack((x_test,)*3, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.normalization import BatchNormalization\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation = 'relu',input_shape=(28, 28 ,3)))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.20))\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_41 (Conv2D)           (None, 26, 26, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 24)                3096      \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 24)                0         \n",
      "=================================================================\n",
      "Total params: 103,576\n",
      "Trainable params: 103,576\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19218 samples, validate on 8237 samples\n",
      "Epoch 1/10\n",
      "19218/19218 [==============================] - 60s 3ms/step - loss: 2.5578 - acc: 0.2240 - val_loss: 1.6237 - val_acc: 0.4588\n",
      "Epoch 2/10\n",
      "19218/19218 [==============================] - 58s 3ms/step - loss: 1.1794 - acc: 0.6035 - val_loss: 0.8265 - val_acc: 0.7207\n",
      "Epoch 3/10\n",
      "19218/19218 [==============================] - 55s 3ms/step - loss: 0.6556 - acc: 0.7789 - val_loss: 0.5202 - val_acc: 0.8249\n",
      "Epoch 4/10\n",
      "19218/19218 [==============================] - 53s 3ms/step - loss: 0.4151 - acc: 0.8639 - val_loss: 0.3106 - val_acc: 0.8893\n",
      "Epoch 5/10\n",
      "19218/19218 [==============================] - 55s 3ms/step - loss: 0.2496 - acc: 0.9232 - val_loss: 0.2091 - val_acc: 0.9354\n",
      "Epoch 6/10\n",
      "19218/19218 [==============================] - 56s 3ms/step - loss: 0.1585 - acc: 0.9534 - val_loss: 0.1426 - val_acc: 0.9548\n",
      "Epoch 7/10\n",
      "19218/19218 [==============================] - 49s 3ms/step - loss: 0.0974 - acc: 0.9737 - val_loss: 0.0784 - val_acc: 0.9801\n",
      "Epoch 8/10\n",
      "19218/19218 [==============================] - 48s 3ms/step - loss: 0.0621 - acc: 0.9858 - val_loss: 0.0526 - val_acc: 0.9882\n",
      "Epoch 9/10\n",
      "19218/19218 [==============================] - 49s 3ms/step - loss: 0.0479 - acc: 0.9889 - val_loss: 0.0646 - val_acc: 0.9832\n",
      "Epoch 10/10\n",
      "19218/19218 [==============================] - 48s 3ms/step - loss: 0.0327 - acc: 0.9922 - val_loss: 0.0294 - val_acc: 0.9945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a80f15c828>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_data = (x_test, y_test), epochs=10, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7915504740658115"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels = test['label']\n",
    "test.drop('label', axis = 1, inplace = True)\n",
    "test_images = test.values\n",
    "test_images = np.array([np.reshape(i, (28, 28)) for i in test_images])\n",
    "test_images = np.array([i.flatten() for i in test_images])\n",
    "test_labels = label_binrizer.fit_transform(test_labels)\n",
    "test_images = test_images.reshape(test_images.shape[0], 28, 28)\n",
    "test_images = np.stack((test_images,)*3, axis=-1)\n",
    "y_pred = model.predict(test_images)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_labels, y_pred.round())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.865867261572783"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(test_images)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_labels, y_pred.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output nodes names are:  ['output_node0']\n",
      "INFO:tensorflow:Froze 12 variables.\n",
      "INFO:tensorflow:Converted 12 variables to const ops.\n",
      "saved the constant graph (ready for inference) at:  tensorflow_model/saved_model_path.pb\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.framework import graph_io\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "import os.path as osp\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "model = load_model(\"model.h5\")\n",
    "nb_classes = 1 # The number of output nodes in the model\n",
    "prefix_output_node_names_of_final_network = 'output_node'\n",
    "\n",
    "K.set_learning_phase(0)\n",
    "\n",
    "pred = [None]*nb_classes\n",
    "pred_node_names = [None]*nb_classes\n",
    "for i in range(nb_classes):\n",
    "    pred_node_names[i] = prefix_output_node_names_of_final_network+str(i)\n",
    "    pred[i] = tf.identity(model.output[i], name=pred_node_names[i])\n",
    "print('output nodes names are: ', pred_node_names)\n",
    "\n",
    "sess = K.get_session()\n",
    "output_fld = 'tensorflow_model/'\n",
    "if not os.path.isdir(output_fld):\n",
    "    os.mkdir(output_fld)\n",
    "output_graph_name = \"saved_model_path\" + '.pb'\n",
    "output_graph_suffix = '_inference'\n",
    "\n",
    "constant_graph = graph_util.convert_variables_to_constants(sess, sess.graph.as_graph_def(), pred_node_names)\n",
    "graph_io.write_graph(constant_graph, output_fld, output_graph_name, as_text=False)\n",
    "print('saved the constant graph (ready for inference) at: ', osp.join(output_fld, output_graph_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_graph_nodes(filename):\n",
    "    import tensorflow as tf\n",
    "    g = tf.GraphDef()\n",
    "    g.ParseFromString(open(filename, 'rb').read())\n",
    "    print()\n",
    "    print(filename)\n",
    "    print(\"=======================INPUT=========================\")\n",
    "    print([n for n in g.node if n.name.find('input') != -1])\n",
    "    print(\"=======================OUTPUT========================\")\n",
    "    print([n for n in g.node if n.name.find('output') != -1])\n",
    "    print(\"===================KERAS_LEARNING=====================\")\n",
    "    print([n for n in g.node if n.name.find('keras_learning_phase') != -1])\n",
    "    print(\"======================================================\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\mirza914\\Downloads\\acad_4_2\\SDPD\\Project\\tensorflow_model\\saved_model_path.pb\n",
      "=======================INPUT=========================\n",
      "[name: \"dropout_1/keras_learning_phase/input\"\n",
      "op: \"Const\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_BOOL\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"value\"\n",
      "  value {\n",
      "    tensor {\n",
      "      dtype: DT_BOOL\n",
      "      tensor_shape {\n",
      "      }\n",
      "      bool_val: false\n",
      "    }\n",
      "  }\n",
      "}\n",
      ", name: \"conv2d_13_input_1\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_FLOAT\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "      dim {\n",
      "        size: -1\n",
      "      }\n",
      "      dim {\n",
      "        size: 28\n",
      "      }\n",
      "      dim {\n",
      "        size: 28\n",
      "      }\n",
      "      dim {\n",
      "        size: 3\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "]\n",
      "=======================OUTPUT========================\n",
      "[name: \"output_node0\"\n",
      "op: \"Identity\"\n",
      "input: \"strided_slice\"\n",
      "attr {\n",
      "  key: \"T\"\n",
      "  value {\n",
      "    type: DT_FLOAT\n",
      "  }\n",
      "}\n",
      "]\n",
      "===================KERAS_LEARNING=====================\n",
      "[name: \"dropout_1/keras_learning_phase/input\"\n",
      "op: \"Const\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_BOOL\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"value\"\n",
      "  value {\n",
      "    tensor {\n",
      "      dtype: DT_BOOL\n",
      "      tensor_shape {\n",
      "      }\n",
      "      bool_val: false\n",
      "    }\n",
      "  }\n",
      "}\n",
      ", name: \"dropout_1/keras_learning_phase\"\n",
      "op: \"PlaceholderWithDefault\"\n",
      "input: \"dropout_1/keras_learning_phase/input\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_BOOL\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "]\n",
      "======================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_graph_nodes(\"C:\\\\Users\\\\mirza914\\\\Downloads\\\\acad_4_2\\\\SDPD\\\\Project\\\\tensorflow_model\\\\saved_model_path.pb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import save_model,load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model=model,filepath='model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model=load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
